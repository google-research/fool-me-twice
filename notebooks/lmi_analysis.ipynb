{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnalyzeLMI",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKB8YaRk05Sl",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/fool-me-twice/blob/master/notebooks/lmi_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-07bRHwv0C7L",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The Google AI Language Team Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpOxRRH0BCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeG9Kj73ck6A"
      },
      "source": [
        "Uses the LMI method of https://www.aclweb.org/anthology/D19-1341 to compare FEVER and FM2 \"artefacts\" at the bigram level.\n",
        "\n",
        "LMI for a bigram $b$ and a label $l$ is defined as $LMI(b, l) = p(b, l)\\cdot \\log(\\frac{p(l\\mid b)}{p(l)})$, with the probabilities computed using the empirical counts for the dev / train set, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXCG2XARORZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31af95be-9703-41f9-8805-9dba2f0cecf3"
      },
      "source": [
        "import collections\n",
        "import json\n",
        "import requests\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsbP_5tkN1OP"
      },
      "source": [
        "def fetch_dataset(url_path):\n",
        "  examples = []\n",
        "  data = requests.get(url_path)\n",
        "  for l in data.content.decode('utf-8').split('\\n'):\n",
        "    if not l:\n",
        "      continue    \n",
        "    examples.append(json.loads(l))\n",
        "  return examples\n",
        "\n",
        "fm2_dev_dataset = fetch_dataset('https://raw.githubusercontent.com/google-research/fool-me-twice/blob/master/dataset/dev.jsonl')\n",
        "fm2_train_dataset = fetch_dataset('https://raw.githubusercontent.com/google-research/fool-me-twice/blob/master/dataset/train.jsonl')\n",
        "\n",
        "fever_dev_dataset = fetch_dataset('https://storage.googleapis.com/fool-me-twice-media/data/fever/dev.jsonl')\n",
        "fever_train_dataset = fetch_dataset('https://storage.googleapis.com/fool-me-twice-media/data/fever/train.jsonl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Em9LJrtOUu0"
      },
      "source": [
        "def safe_log(x):\n",
        "  if x == 0:\n",
        "    return 0\n",
        "  return math.log(x)\n",
        "\n",
        "def compute_lmi(examples):\n",
        "  bigrams = collections.defaultdict(int)\n",
        "  bigram_labels = collections.defaultdict(int)\n",
        "  labels = collections.defaultdict(int)\n",
        "  num_claims = 0\n",
        "\n",
        "  for example in examples:\n",
        "    num_claims += 1\n",
        "    tokens = nltk.word_tokenize(example['text'].lower())\n",
        "    label = example['label']\n",
        "    labels[label] += 1\n",
        "    for i in range(len(tokens) - 1):\n",
        "      bigram = (tokens[i], tokens[i+1]) \n",
        "      bigrams[bigram] += 1\n",
        "      bigram_labels[(bigram, label)] += 1\n",
        "  \n",
        "  def p_l_given_b(bigram, label):\n",
        "    return bigram_labels[(bigram, label)] / bigrams[bigram]\n",
        "  \n",
        "  def p_b_and_l(bigram, label):\n",
        "    return bigram_labels[(bigram, label)] / num_claims\n",
        "\n",
        "  def p_l(label):\n",
        "    return labels[label] / num_claims\n",
        "\n",
        "  def lmi(bigram, label):\n",
        "    return p_b_and_l(bigram=bigram, label=label) * safe_log(p_l_given_b(bigram=bigram, label=label) / p_l(label))\n",
        "\n",
        "  lmi_per_label = {}\n",
        "  for label in labels:\n",
        "    lmi_per_label[label] = {\n",
        "        bigram: lmi(bigram=bigram, label=label) for bigram in bigrams\n",
        "    }\n",
        "\n",
        "  return lmi_per_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlEks9pZYsd"
      },
      "source": [
        "fm2_dev_lmi = compute_lmi(fm2_dev_dataset)\n",
        "fm2_train_lmi = compute_lmi(fm2_train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQ1zGJDZXTe"
      },
      "source": [
        "fever_dev_lmi = compute_lmi(fever_dev_dataset)\n",
        "fever_train_lmi = compute_lmi(fever_train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IITB3zRWZqaU"
      },
      "source": [
        "def compare_dev_and_train(train_data, dev_data, n=10):\n",
        "    for label in train_data:\n",
        "      highest_train = sorted(train_data[label].items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "      highest_dev = sorted(dev_data[label].items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "      print(f'{label}')\n",
        "\n",
        "      def make_row(bigram, train_score, dev_score):\n",
        "        if train_score is None:\n",
        "          train_score = \"NONE\"\n",
        "        else:\n",
        "          train_score = int(train_score * 10**5)\n",
        "        if dev_score is None:\n",
        "          dev_score = \"NONE\"\n",
        "        else:\n",
        "          dev_score = int(dev_score * 10**5)\n",
        "\n",
        "        print(f'{\" \".join(bigram)} & ${train_score}$ & ${dev_score}$ \\\\\\\\')\n",
        "\n",
        "      def remove_bigram_and_get_score(bigram, list):\n",
        "        new_list = [(b, s) for (b, s) in list if b != bigram]\n",
        "        score_list = [s for (b, s) in list if b == bigram]\n",
        "        if score_list:\n",
        "          score = score_list[0]\n",
        "        else:\n",
        "          score = None\n",
        "        return (new_list, score)\n",
        "\n",
        "      while highest_train and highest_dev:\n",
        "        next_bigram = max(highest_train[0], highest_dev[0], key=lambda x: x[1])[0]\n",
        "        highest_train, train_score = remove_bigram_and_get_score(next_bigram, highest_train)\n",
        "        highest_dev, dev_score = remove_bigram_and_get_score(next_bigram, highest_dev)\n",
        "        make_row(bigram=next_bigram, train_score=train_score, dev_score=dev_score)\n",
        "\n",
        "\n",
        "      if highest_train:\n",
        "        for (bigram, train_score) in highest_train:\n",
        "          make_row(bigram=bigram, \n",
        "                   train_score=train_score,\n",
        "                   dev_score=None)          \n",
        "      else:\n",
        "        for (bigram, dev_score) in highest_dev:\n",
        "          make_row(bigram=bigram, \n",
        "                   train_score=None,\n",
        "                   dev_score=dev_score)          \n",
        "\n",
        "      print()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMSK_82RYze-",
        "outputId": "2f9ff3f0-302c-4bff-c63e-3c3d3f36a327"
      },
      "source": [
        "print('FEVER')\n",
        "compare_dev_and_train(train_data=fever_train_lmi, dev_data=fever_dev_lmi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FEVER\n",
            "SUPPORTS\n",
            "is a & $482$ & $625$ \\\\\n",
            "in the & $343$ & $499$ \\\\\n",
            "in a & $481$ & $437$ \\\\\n",
            "is an & $362$ & $455$ \\\\\n",
            "a film & $297$ & $428$ \\\\\n",
            "was in & $402$ & $NONE$ \\\\\n",
            "an american & $280$ & $375$ \\\\\n",
            "a person & $302$ & $353$ \\\\\n",
            "was a & $319$ & $285$ \\\\\n",
            "there is & $NONE$ & $302$ \\\\\n",
            "of the & $NONE$ & $289$ \\\\\n",
            "starred in & $254$ & $NONE$ \\\\\n",
            "\n",
            "REFUTES\n",
            "is not & $1420$ & $938$ \\\\\n",
            "is only & $622$ & $938$ \\\\\n",
            "did not & $859$ & $528$ \\\\\n",
            "not a & $775$ & $481$ \\\\\n",
            "was not & $729$ & $NONE$ \\\\\n",
            "incapable of & $721$ & $710$ \\\\\n",
            "only a & $455$ & $717$ \\\\\n",
            "is incapable & $474$ & $551$ \\\\\n",
            "was only & $NONE$ & $536$ \\\\\n",
            "has only & $447$ & $NONE$ \\\\\n",
            "yet to & $420$ & $384$ \\\\\n",
            "of being & $NONE$ & $385$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYw27aEGbVB7",
        "outputId": "3589aab7-e20d-4d90-a5df-38f8e8efad3e"
      },
      "source": [
        "print('FM2')\n",
        "compare_dev_and_train(train_data=fm2_train_lmi, dev_data=fm2_dev_lmi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FM2\n",
            "SUPPORTS\n",
            "in the & $354$ & $1286$ \\\\\n",
            "of a & $NONE$ & $464$ \\\\\n",
            "in which & $NONE$ & $461$ \\\\\n",
            "one of & $418$ & $NONE$ \\\\\n",
            "book of & $NONE$ & $403$ \\\\\n",
            "has been & $365$ & $NONE$ \\\\\n",
            ", the & $NONE$ & $356$ \\\\\n",
            "in a & $NONE$ & $352$ \\\\\n",
            "the novel & $NONE$ & $351$ \\\\\n",
            "and his & $NONE$ & $351$ \\\\\n",
            "the united & $NONE$ & $348$ \\\\\n",
            "the scarlet & $NONE$ & $345$ \\\\\n",
            "more than & $268$ & $NONE$ \\\\\n",
            "to be & $228$ & $NONE$ \\\\\n",
            "of the & $222$ & $NONE$ \\\\\n",
            "to the & $173$ & $NONE$ \\\\\n",
            "with a & $166$ & $NONE$ \\\\\n",
            "from the & $154$ & $NONE$ \\\\\n",
            "years . & $138$ & $NONE$ \\\\\n",
            "\n",
            "REFUTES\n",
            "by a & $NONE$ & $562$ \\\\\n",
            "mad , & $NONE$ & $502$ \\\\\n",
            ", mad & $NONE$ & $502$ \\\\\n",
            "on the & $NONE$ & $473$ \\\\\n",
            "innocent iii & $NONE$ & $467$ \\\\\n",
            "statue of & $NONE$ & $426$ \\\\\n",
            "for his & $NONE$ & $407$ \\\\\n",
            "pope innocent & $NONE$ & $407$ \\\\\n",
            "mary , & $NONE$ & $365$ \\\\\n",
            "queen of & $NONE$ & $365$ \\\\\n",
            "the second & $338$ & $NONE$ \\\\\n",
            "is a & $312$ & $NONE$ \\\\\n",
            "was a & $307$ & $NONE$ \\\\\n",
            "was the & $306$ & $NONE$ \\\\\n",
            "is the & $233$ & $NONE$ \\\\\n",
            "of his & $200$ & $NONE$ \\\\\n",
            "has never & $189$ & $NONE$ \\\\\n",
            "was born & $177$ & $NONE$ \\\\\n",
            "written by & $165$ & $NONE$ \\\\\n",
            "about a & $162$ & $NONE$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
